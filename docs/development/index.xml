<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>开发与部署指南 on FastGPT</title><link>/docs/development/</link><description>Recent content in 开发与部署指南 on FastGPT</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><atom:link href="/docs/development/index.xml" rel="self" type="application/rss+xml"/><item><title>快速开始本地开发</title><link>/docs/development/intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/intro/</guid><description>本文档介绍了如何设置开发环境以构建和测试 FastGPT。
前置依赖项 link您需要在计算机上安装和配置以下依赖项才能构建 FastGPT：
Git Docker（构建镜像） Node.js v18.x (不推荐最新的，可能有兼容问题) pnpm 版本 8.x.x 开始本地开发 link check_circle 用户默认的时区为 Asia/Shanghai,非 linux 环境时候，获取系统时间会异常，本地开发时候，可以将用户的时区调整成 UTC（+0）。 建议先服务器装好数据库，再进行本地开发。 1. Fork 存储库 link您需要 Fork 存储库。
2. 克隆存储库 link克隆您在 GitHub 上 Fork 的存储库：
git clone git@github.com:&amp;lt;github_username&amp;gt;/FastGPT.git 目录简要说明
projects 目录下为 FastGPT 应用代码。其中 app 为 FastGPT 核心应用。（后续可能会引入其他应用） NextJS 框架前后端放在一起，API 服务位于 src/pages/api 目录内。 packages 目录为共用代码，通过 workspace 被注入到 projects 中，已配置 monorepo 自动注入，无需额外打包。 3. 安装数据库 link第一次开发，需要先部署数据库，建议本地开发可以随便找一台 2C2G 的轻量小数据库实践。数据库部署教程：Docker 快速部署。部署完了，可以本地访问其数据库。
Mongo 数据库需要注意，需要注意在连接地址中增加 directConnection=true 参数，才能连接上副本集的数据库。</description></item><item><title>Sealos 一键部署</title><link>/docs/development/sealos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/sealos/</guid><description>部署架构图 link 多模型支持 linkFastGPT 使用了 one-api 项目来管理模型池，其可以兼容 OpenAI 、Azure 、国内主流模型和本地模型等。
可参考：Sealos 快速部署 OneAPI
一键部署 linkSealos 的服务器在国外，不需要额外处理网络问题，无需服务器、无需魔法、无需域名，支持高并发 &amp;amp; 动态伸缩。点击以下按钮即可一键部署 👇
由于需要部署数据库，部署完后需要等待 2~4 分钟才能正常访问。默认用了最低配置，首次访问时会有些慢。
点击 Sealos 提供的外网地址即可打开 FastGPT 的可视化界面。
登录 link用户名：root
密码是刚刚一键部署时设置的root_password
修改配置文件和环境变量 link在 Sealos 中，你可以打开应用管理（App Launchpad）看到部署的 FastGPT，可以打开数据库（Database）看到对应的数据库。
在应用管理中，选中 FastGPT，点击变更，可以看到对应的环境变量和配置文件。
🤖
在 Sealos 上，FastGPT 一共运行了 1 个服务和 2 个数据库，如暂停和删除请注意数据库一同操作。（你可以白天启动，晚上暂停它们，省钱大法）
更新 link点击变更或重启会自动拉取镜像更新，请确保镜像tag正确。建议不要使用latest，改成固定版本号。
Sealos 使用 link简介 linkFastGPT 商业版共包含了2个应用（fastgpt, fastgpt-plus）和2个数据库，使用多 Api Key 时候需要安装 OneAPI（一个应用和一个数据库），总计3个应用和3个数据库。
点击右侧的详情，可以查看对应应用的详细信息。
如何更新/升级 FastGPT link升级脚本文档先看下文档，看下需要升级哪个版本。注意，不要跨版本升级！！！！！
例如，目前是4.5 版本，要升级到4.5.1，就先把镜像版本改成v4.5.1，执行一下升级脚本，等待完成后再继续升级。如果目标版本不需要执行初始化，则可以跳过。
升级步骤：
查看更新文档，确认要升级的版本，避免跨版本升级。 打开 sealos 的应用管理 有2个应用 fastgpt ， fastgpt-pro 点击对应应用右边3个点，变更。或者点详情后右上角的变更。 修改镜像的版本号 点击变更/重启，会自动拉取最新镜像进行更新 执行对应版本的初始化脚本(如果有) 如何获取 FastGPT 访问链接 link打开对应的应用，点击外网访问地址。</description></item><item><title>Docker Compose 快速部署</title><link>/docs/development/docker/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/docker/</guid><description>推荐配置 link 环境 最低配置（单节点） 推荐配置 测试 2c2g 2c4g 100w 组向量 4c8g 50GB 4c16g 50GB 500w 组向量 8c32g 16c64g 200GB 部署架构图 link 1. 准备好代理环境（国外服务器可忽略） link确保可以访问 OpenAI，具体方案可以参考：代理方案。或直接在 Sealos 上 部署 OneAPI，既解决代理问题也能实现多 Key 轮询、接入其他大模型。
2. 多模型支持 linkFastGPT 使用了 one-api 项目来管理模型池，其可以兼容 OpenAI 、Azure 、国内主流模型和本地模型等。
可选择 Sealos 快速部署 OneAPI，更多部署方法可参考该项目的 README，也可以直接通过以下按钮一键部署：
一、安装 Docker 和 docker-compose link Linux MacOS Windows # 安装 Docker curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun systemctl enable --now docker # 安装 docker-compose curl -L https://github.</description></item><item><title>配置文件介绍</title><link>/docs/development/configuration/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/configuration/</guid><description>由于环境变量不利于配置复杂的内容，新版 FastGPT 采用了 ConfigMap 的形式挂载配置文件，你可以在 projects/app/data/config.json 看到默认的配置文件。可以参考 docker-compose 快速部署 来挂载配置文件。
开发环境下，你需要将示例配置文件 config.json 复制成 config.local.json 文件才会生效。
这个配置文件中包含了系统参数和各个模型配置，使用时务必去掉注释!!!!!!!!!!!!!!
4.6.8+ 版本新配置文件 linkllm模型全部合并
{ &amp;#34;feConfigs&amp;#34;: { &amp;#34;lafEnv&amp;#34;: &amp;#34;https://laf.dev&amp;#34; // laf环境。 https://laf.run （杭州阿里云） ,或者私有化的laf环境。如果使用 Laf openapi 功能，需要最新版的 laf 。 }, &amp;#34;systemEnv&amp;#34;: { &amp;#34;vectorMaxProcess&amp;#34;: 15, &amp;#34;qaMaxProcess&amp;#34;: 15, &amp;#34;pgHNSWEfSearch&amp;#34;: 100 // 向量搜索参数。越大，搜索越精确，但是速度越慢。设置为100，有99%&amp;#43;精度。 }, &amp;#34;llmModels&amp;#34;: [ { &amp;#34;model&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;, // 模型名(对应OneAPI中渠道的模型名) &amp;#34;name&amp;#34;: &amp;#34;gpt-3.5-turbo&amp;#34;, // 别名 &amp;#34;avatar&amp;#34;: &amp;#34;/imgs/model/openai.svg&amp;#34;, // 模型的logo &amp;#34;maxContext&amp;#34;: 16000, // 最大上下文 &amp;#34;maxResponse&amp;#34;: 4000, // 最大回复 &amp;#34;quoteMaxToken&amp;#34;: 13000, // 最大引用内容 &amp;#34;maxTemperature&amp;#34;: 1.</description></item><item><title>使用 One API 接入 Azure、ChatGLM 和本地模型</title><link>/docs/development/one-api/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/one-api/</guid><description>默认情况下，FastGPT 只配置了 GPT 的模型，如果你需要接入其他模型，需要进行一些额外配置。 One API 是一个 OpenAI 接口管理 &amp;amp; 分发系统，可以通过标准的 OpenAI API 格式访问所有的大模型，开箱即用。 FastGPT 可以通过接入 One API 来实现对不同大模型的支持。One API 的部署方法也很简单。 FastGPT 与 One API 关系 link可以把 One API 当做一个网关。
部署 linkDocker 版本 link已加入最新的 docker-compose.yml 文件中。
Sealos - MySQL 版本 linkMySQL 版本支持多实例，高并发。
直接点击以下按钮即可一键部署 👇
部署完后会跳转「应用管理」，数据库在另一个应用「数据库」中。需要等待 1~3 分钟数据库运行后才能访问成功。
Sealos - SqlLite 版本 linkSqlLite 版本不支持多实例，适合个人小流量使用，但是价格非常便宜。
1. 点击打开 Sealos 公有云
2. 打开 AppLaunchpad(应用管理) 工具
3. 点击创建新应用
4. 填写对应参数
镜像：ghcr.io/songquanpeng/one-api:latest
打开外网访问开关后，Sealos 会自动分配一个可访问的地址，不需要自己配置。
填写完参数后，点击右上角部署即可。环境变量：</description></item><item><title>私有部署常见问题</title><link>/docs/development/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/docs/development/faq/</guid><description>一、错误排查方式 link遇到问题先按下面方式排查。
docker ps -a 查看所有容器运行状态，检查是否全部 running，如有异常，尝试docker logs 容器名查看对应日志。 容器都运行正常的，docker logs 容器名 查看报错日志 带有requestId的，都是 OneAPI 提示错误，大部分都是因为模型接口报错。 无法解决时，可以找找Issue，或新提 Issue，私有部署错误，务必提供详细的日志，否则很难排查。 二、通用问题 link能否纯本地运行 link可以。需要准备好向量模型和LLM模型。
其他模型没法进行问题分类/内容提取 link 看日志。如果提示 JSON invalid，not support tool 之类的，说明该模型不支持工具调用或函数调用，需要设置toolChoice=false和functionCall=false，就会默认走提示词模式。目前内置提示词仅针对了商业模型API进行测试。问题分类基本可用，内容提取不太行。 如果已经配置正常，并且没有错误日志，则说明可能提示词不太适合该模型，可以通过修改customCQPrompt来自定义提示词。 页面崩溃 link 关闭翻译 检查配置文件是否正常加载，如果没有正常加载会导致缺失系统信息，在某些操作下会导致空指针。（95%情况是配置文件不对，可以F12打开控制台，看具体的空指针情况） 某些api不兼容问题（较少） 开启内容补全后，响应速度变慢 link 问题补全需要经过一轮AI生成。 会进行3~5轮的查询，如果数据库性能不足，会有明显影响。 对话接口报错或返回为空(core.chat.Chat API is error or undefined) link 检查 AI 的 key 问题：通过 curl 请求看是否正常。务必用 stream=true 模式。并且 maxToken 等相关参数尽量一致。 如果是国内模型，可能是命中风控了。 查看模型请求日志，检查出入参数是否异常。 # curl 例子。 curl --location --request POST &amp;#39;https://xxx.cn/v1/chat/completions&amp;#39; \ --header &amp;#39;Authorization: Bearer sk-xxxx&amp;#39; \ --header &amp;#39;Content-Type: application/json&amp;#39; \ --data-raw &amp;#39;{ &amp;#34;model&amp;#34;: &amp;#34;gpt-3.</description></item></channel></rss>